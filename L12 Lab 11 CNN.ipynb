{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9f959230",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "877dcb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#from keras.optimizers import SGD\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.constraints import maxnorm\n",
    "from keras.layers import Activation\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "049da3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698913c3",
   "metadata": {},
   "source": [
    "I'll be using the Cifra10 dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "fe652bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "501c6f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare variables\n",
    "batch_size = 32  #  smaller batch size means more updates in one epoch\n",
    "num_classes = 10 # number of cifar-10 dataset classes\n",
    "epochs = 5 # repeat 5 times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91d93f4",
   "metadata": {},
   "source": [
    "- The pixel values are in the range of 0 to 255 for each of the red, green and blue channels.\n",
    "- Because the input values are well understood, we can easily normalize to the range 0 to 1 by dividing each value by the maximum observation which is 255.\n",
    "- The data is loaded as integers, so we must cast it to float point values in order to perform the division."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "6c791dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np_utils.to_categorical(y_train, num_classes)\n",
    "y_test = np_utils.to_categorical(y_test, num_classes)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train  /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67d35a7",
   "metadata": {},
   "source": [
    "CNN architecture 1 :\n",
    "- We will use a model with 2 convolutional layers followed by max pooling and a flattening out of the network to fully connected layers to make predictions : \n",
    "    - Convolutional input layer, 32 feature maps with a size of 3×3, a rectifier activation function\n",
    "    - Max Pool layer with size 2×2\n",
    "    - Convolutional input layer, 64 feature maps with a size of 3×3, a rectifier activation function\n",
    "    - Max Pool layer with size 2×2\n",
    "    - Flatten layer\n",
    "    - Fully connected layer with 64 units and a rectifier activation function\n",
    "    - Fully connected output layer with 10 units and a softmax activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "aec868e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_20 (Conv2D)          (None, 30, 30, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  (None, 15, 15, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 13, 13, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPoolin  (None, 6, 6, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 2304)              0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 64)                147520    \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 167,562\n",
      "Trainable params: 167,562\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=X_train.shape[1:]))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# Adding the fully connected layers to CNN\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "#model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d58cfb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "93fe37db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 29s 17ms/step - loss: 1.5016 - accuracy: 0.4616\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 1.1228 - accuracy: 0.6077\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 0.9813 - accuracy: 0.6577\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 0.8848 - accuracy: 0.6931\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 35s 22ms/step - loss: 0.8080 - accuracy: 0.7202\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16e2de20ee0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1459fd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8f0cc564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy: 0.7309\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "#accuracy on training set\n",
    "y_pred1_train = model.predict(X_train)\n",
    "print(\"Training set accuracy:\", metrics.accuracy_score(np.argmax(y_train, axis=1), np.argmax(y_pred1_train, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5c956a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.6728\n"
     ]
    }
   ],
   "source": [
    "#accuracy on test set \n",
    "print(\"Test set accuracy:\", metrics.accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9a0bc5",
   "metadata": {},
   "source": [
    "10-fold cross-validation on the training set :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "af59deb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 12s 8ms/step - loss: 39.5317 - accuracy: 0.1099\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 39.5317 - accuracy: 0.1099\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 39.5317 - accuracy: 0.1099\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 39.5317 - accuracy: 0.1099\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 39.5317 - accuracy: 0.1099\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 39.5317 - accuracy: 0.1099\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 39.5317 - accuracy: 0.1099\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 39.5317 - accuracy: 0.1099\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 39.5317 - accuracy: 0.1099\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 39.5317 - accuracy: 0.1099\n",
      "Estimated Accuracy 19.821 (19.711)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "n_folds = 10\n",
    "cv_scores2 = list()\n",
    "for _ in range(n_folds):\n",
    "    (X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "    # evaluate model\n",
    "    val_acc = model.evaluate(X_train, y_train)\n",
    "    cv_scores2.append(val_acc)\n",
    "    \n",
    "print('Estimated Accuracy %.3f (%.3f)' % (np.mean(cv_scores2), np.std(cv_scores2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac8d530",
   "metadata": {},
   "source": [
    "It was difficult to do the kfold cross validation since the dataset used wasn't a csv file that I could use train_test_split with easily, which why it just ended up being the same split used for every fold."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b172135",
   "metadata": {},
   "source": [
    "Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "591be73b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[771,  32,  50,   7,  28,  15,  16,  12,  14,  55],\n",
       "       [ 22, 839,   4,   6,   3,   8,  11,   3,   8,  96],\n",
       "       [ 67,   9, 407,  45, 184, 123, 102,  35,   6,  22],\n",
       "       [ 25,  23,  25, 389,  94, 274,  99,  40,   7,  24],\n",
       "       [ 21,   2,  26,  44, 704,  37,  70,  76,   6,  14],\n",
       "       [ 14,   5,  23, 102,  57, 680,  42,  51,   5,  21],\n",
       "       [  5,  10,  23,  28,  45,  33, 834,   4,   2,  16],\n",
       "       [ 19,   2,  13,  19,  94,  83,   9, 726,   3,  32],\n",
       "       [155,  93,  11,  13,  15,  19,  17,  17, 568,  92],\n",
       "       [ 27, 102,   5,   8,   7,  14,   7,  16,   4, 810]], dtype=int64)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "confusion_matrix(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9d622f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.77      0.73      1000\n",
      "           1       0.75      0.84      0.79      1000\n",
      "           2       0.69      0.41      0.51      1000\n",
      "           3       0.59      0.39      0.47      1000\n",
      "           4       0.57      0.70      0.63      1000\n",
      "           5       0.53      0.68      0.59      1000\n",
      "           6       0.69      0.83      0.76      1000\n",
      "           7       0.74      0.73      0.73      1000\n",
      "           8       0.91      0.57      0.70      1000\n",
      "           9       0.69      0.81      0.74      1000\n",
      "\n",
      "    accuracy                           0.67     10000\n",
      "   macro avg       0.68      0.67      0.67     10000\n",
      "weighted avg       0.68      0.67      0.67     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4ac3ccbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Score of the classifier is: 0.6847148585151126\n",
      "Recall Score of the classifier is: 0.6728\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "print(f\"Precision Score of the classifier is: {precision_score(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1), average ='weighted')}\")\n",
    "#recall\n",
    "from sklearn.metrics import recall_score\n",
    "print(f\"Recall Score of the classifier is: {recall_score(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1),average ='weighted')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89facb60",
   "metadata": {},
   "source": [
    "CNN architecture 2\n",
    "- We will use a model with 1 convolutional layer followed by max pooling and a flattening out of the network to fully connected layers to make predictions : \n",
    "    - Convolutional input layer, 32 feature maps with a size of 3×3, a rectifier activation function\n",
    "    - Max Pool layer with size 2×2\n",
    "    - Flatten layer\n",
    "    - Fully connected layer with 64 units and a rectifier activation function\n",
    "    - Fully connected output layer with 10 units and a softmax activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "48c96f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model2():\n",
    "\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(32, (3, 3), padding='same', input_shape=X_train.shape[1:])) \n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "dad3a596",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 24s 15ms/step - loss: 1.5272 - accuracy: 0.4568\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 26s 16ms/step - loss: 1.1951 - accuracy: 0.5800\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 26s 17ms/step - loss: 1.0760 - accuracy: 0.6246\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 26s 17ms/step - loss: 0.9985 - accuracy: 0.6540\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 25s 16ms/step - loss: 0.9376 - accuracy: 0.6742\n",
      "Training set accuracy: 0.7055\n",
      "Test set accuracy: 0.635\n"
     ]
    }
   ],
   "source": [
    "cnn2 = model2()\n",
    "cnn2.fit(X_train, y_train, batch_size=batch_size, epochs=epochs)\n",
    "y_pred4_train = cnn2.predict(X_train)\n",
    "print(\"Training set accuracy:\", metrics.accuracy_score(np.argmax(y_train, axis=1), np.argmax(y_pred4_train, axis=1)))\n",
    "y_pred4 = cnn2.predict(X_test)\n",
    "print(\"Test set accuracy:\", metrics.accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_pred4, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "30d2ae62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[736,  22,  48,  18,  23,   4,   8,   6,  98,  37],\n",
       "       [ 46, 742,   3,  13,   7,   5,   4,   5,  56, 119],\n",
       "       [102,  13, 361,  71, 257,  72,  42,  45,  25,  12],\n",
       "       [ 43,  10,  48, 449, 171, 145,  52,  33,  29,  20],\n",
       "       [ 33,   6,  39,  55, 759,  25,  35,  33,  12,   3],\n",
       "       [ 25,   6,  49, 174, 129, 514,  15,  61,  18,   9],\n",
       "       [ 17,   5,  28,  95, 166,  22, 630,  10,  12,  15],\n",
       "       [ 39,   5,  26,  52, 115,  73,   2, 665,   4,  19],\n",
       "       [101,  49,   6,  12,   7,  10,   5,   4, 770,  36],\n",
       "       [ 64,  99,  12,  18,  11,  10,   5,  15,  42, 724]], dtype=int64)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(np.argmax(y_test, axis=1), np.argmax(y_pred4, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ce85a8a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.74      0.67      1000\n",
      "           1       0.78      0.74      0.76      1000\n",
      "           2       0.58      0.36      0.45      1000\n",
      "           3       0.47      0.45      0.46      1000\n",
      "           4       0.46      0.76      0.57      1000\n",
      "           5       0.58      0.51      0.55      1000\n",
      "           6       0.79      0.63      0.70      1000\n",
      "           7       0.76      0.67      0.71      1000\n",
      "           8       0.72      0.77      0.75      1000\n",
      "           9       0.73      0.72      0.73      1000\n",
      "\n",
      "    accuracy                           0.64     10000\n",
      "   macro avg       0.65      0.64      0.63     10000\n",
      "weighted avg       0.65      0.64      0.63     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(np.argmax(y_test, axis=1), np.argmax(y_pred4, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f04b9224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Score of the classifier is: 0.6480980358469043\n",
      "Recall Score of the classifier is: 0.635\n"
     ]
    }
   ],
   "source": [
    "print(f\"Precision Score of the classifier is: {precision_score(np.argmax(y_test, axis=1), np.argmax(y_pred4, axis=1), average ='weighted')}\")\n",
    "print(f\"Recall Score of the classifier is: {recall_score(np.argmax(y_test, axis=1), np.argmax(y_pred4, axis=1),average ='weighted')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5bb4e5",
   "metadata": {},
   "source": [
    "CNN architecture 3\n",
    "- We will use a model with 3 convolutional layers followed by max pooling and a flattening out of the network to fully connected layers to make predictions : \n",
    "    - Convolutional input layer, 32 feature maps with a size of 3×3, a rectifier activation function\n",
    "    - Max Pool layer with size 2×2\n",
    "    - Convolutional input layer, 64 feature maps with a size of 3×3, a rectifier activation function\n",
    "    - Max Pool layer with size 2×2\n",
    "    - Convolutional input layer, 64 feature maps with a size of 3×3, a rectifier activation function\n",
    "    - Max Pool layer with size 2×2\n",
    "    - Flatten layer\n",
    "    - Fully connected layer with 64 units and a rectifier activation function\n",
    "    - Fully connected output layer with 10 units and a softmax activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "23b69f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model3():\n",
    "\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(32, (3, 3), padding='same', input_shape=X_train.shape[1:])) \n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e3ea619a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 38s 24ms/step - loss: 1.5786 - accuracy: 0.4275\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 41s 26ms/step - loss: 1.1979 - accuracy: 0.5756\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 41s 26ms/step - loss: 1.0262 - accuracy: 0.6416\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 39s 25ms/step - loss: 0.9161 - accuracy: 0.6819\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 0.8354 - accuracy: 0.7093\n",
      "Training set accuracy: 0.75696\n",
      "Test set accuracy: 0.7051\n"
     ]
    }
   ],
   "source": [
    "cnn3 = model3()\n",
    "cnn3.fit(X_train, y_train, batch_size=batch_size, epochs=epochs)\n",
    "y_pred3_train = cnn3.predict(X_train)\n",
    "print(\"Training set accuracy:\", metrics.accuracy_score(np.argmax(y_train, axis=1), np.argmax(y_pred3_train, axis=1)))\n",
    "y_pred3 = cnn3.predict(X_test)\n",
    "print(\"Test set accuracy:\", metrics.accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_pred3, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "be7a50f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[745,  26,  60,  12,   6,   1,   9,  18,  82,  41],\n",
       "       [ 14, 839,  11,   5,   1,   2,  10,   9,  27,  82],\n",
       "       [ 67,   6, 654,  60,  46,  38,  65,  44,  12,   8],\n",
       "       [ 18,  13, 118, 575,  50,  82,  58,  49,  15,  22],\n",
       "       [ 28,   2, 102,  71, 571,  26,  61, 118,  14,   7],\n",
       "       [ 17,   9, 110, 214,  40, 483,  31,  78,   5,  13],\n",
       "       [  3,   9,  72,  57,  22,   8, 813,   9,   4,   3],\n",
       "       [ 15,   2,  47,  47,  36,  32,  10, 792,   4,  15],\n",
       "       [ 76,  53,  21,  15,   2,   3,   4,   8, 782,  36],\n",
       "       [ 24,  75,  19,  18,   5,   3,   7,  21,  31, 797]], dtype=int64)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(np.argmax(y_test, axis=1), np.argmax(y_pred3, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "efedd598",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.74      0.74      1000\n",
      "           1       0.81      0.84      0.82      1000\n",
      "           2       0.54      0.65      0.59      1000\n",
      "           3       0.54      0.57      0.55      1000\n",
      "           4       0.73      0.57      0.64      1000\n",
      "           5       0.71      0.48      0.58      1000\n",
      "           6       0.76      0.81      0.79      1000\n",
      "           7       0.69      0.79      0.74      1000\n",
      "           8       0.80      0.78      0.79      1000\n",
      "           9       0.78      0.80      0.79      1000\n",
      "\n",
      "    accuracy                           0.71     10000\n",
      "   macro avg       0.71      0.71      0.70     10000\n",
      "weighted avg       0.71      0.71      0.70     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(np.argmax(y_test, axis=1), np.argmax(y_pred3, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ff5db287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Score of the classifier is: 0.7102595632577017\n",
      "Recall Score of the classifier is: 0.7051\n"
     ]
    }
   ],
   "source": [
    "print(f\"Precision Score of the classifier is: {precision_score(np.argmax(y_test, axis=1), np.argmax(y_pred3, axis=1), average ='weighted')}\")\n",
    "print(f\"Recall Score of the classifier is: {recall_score(np.argmax(y_test, axis=1), np.argmax(y_pred3, axis=1),average ='weighted')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd4cf48",
   "metadata": {},
   "source": [
    "CNN Architecture 4 \n",
    "- same as architecture 3\n",
    "- changed epoches to 10 instead of 5 when fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ba1dd887",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 36s 23ms/step - loss: 0.7726 - accuracy: 0.7314\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 40s 25ms/step - loss: 0.7238 - accuracy: 0.7474\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 39s 25ms/step - loss: 0.6825 - accuracy: 0.7613\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 40s 26ms/step - loss: 0.6407 - accuracy: 0.7774\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 41s 26ms/step - loss: 0.6114 - accuracy: 0.7891\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 41s 26ms/step - loss: 0.5835 - accuracy: 0.7989\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 39s 25ms/step - loss: 0.5567 - accuracy: 0.8060\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 41s 26ms/step - loss: 0.5337 - accuracy: 0.8149\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 42s 27ms/step - loss: 0.5072 - accuracy: 0.8252\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 40s 26ms/step - loss: 0.4931 - accuracy: 0.8278\n",
      "Training set accuracy: 0.85576\n",
      "Test set accuracy: 0.7212\n"
     ]
    }
   ],
   "source": [
    "cnn3.fit(X_train, y_train, batch_size=batch_size, epochs=10)\n",
    "y_pred5_train = cnn3.predict(X_train)\n",
    "print(\"Training set accuracy:\", metrics.accuracy_score(np.argmax(y_train, axis=1), np.argmax(y_pred5_train, axis=1)))\n",
    "y_pred5 = cnn3.predict(X_test)\n",
    "print(\"Test set accuracy:\", metrics.accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_pred5, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f9a2b719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[777,  10,  36,  10,  12,   3,   8,   8,  63,  73],\n",
       "       [ 22, 734,   6,   7,   4,   4,  11,   5,  33, 174],\n",
       "       [ 75,   2, 554,  54,  92,  77,  78,  20,  17,  31],\n",
       "       [ 29,   2,  47, 500,  60, 172,  75,  46,  31,  38],\n",
       "       [ 28,   0,  41,  58, 699,  35,  50,  64,  10,  15],\n",
       "       [ 21,   2,  45, 116,  52, 628,  41,  55,  10,  30],\n",
       "       [ 12,   1,  23,  41,  24,  18, 849,   7,   6,  19],\n",
       "       [ 24,   2,  23,  23,  57,  44,  14, 765,   6,  42],\n",
       "       [ 84,  15,   4,  10,   5,   3,  10,   7, 808,  54],\n",
       "       [ 26,  24,   8,   6,   0,   8,   5,   9,  16, 898]], dtype=int64)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(np.argmax(y_test, axis=1), np.argmax(y_pred5, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2b5c03df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.78      0.74      1000\n",
      "           1       0.93      0.73      0.82      1000\n",
      "           2       0.70      0.55      0.62      1000\n",
      "           3       0.61      0.50      0.55      1000\n",
      "           4       0.70      0.70      0.70      1000\n",
      "           5       0.63      0.63      0.63      1000\n",
      "           6       0.74      0.85      0.79      1000\n",
      "           7       0.78      0.77      0.77      1000\n",
      "           8       0.81      0.81      0.81      1000\n",
      "           9       0.65      0.90      0.76      1000\n",
      "\n",
      "    accuracy                           0.72     10000\n",
      "   macro avg       0.73      0.72      0.72     10000\n",
      "weighted avg       0.73      0.72      0.72     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(np.argmax(y_test, axis=1), np.argmax(y_pred5, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "37674378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Score of the classifier is: 0.7254516904808731\n",
      "Recall Score of the classifier is: 0.7212\n"
     ]
    }
   ],
   "source": [
    "print(f\"Precision Score of the classifier is: {precision_score(np.argmax(y_test, axis=1), np.argmax(y_pred5, axis=1), average ='weighted')}\")\n",
    "print(f\"Recall Score of the classifier is: {recall_score(np.argmax(y_test, axis=1), np.argmax(y_pred5, axis=1),average ='weighted')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa54805",
   "metadata": {},
   "source": [
    " metrics summary table : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c1f5d5e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"10.PNG\" width=\"400\" height=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"10.PNG\", width=400, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248da508",
   "metadata": {},
   "source": [
    "- Architecture 4 performed best overall, it had the most accurate predictions and a balanced precision and recall.\n",
    "- Architecture 4 had similar number of convolution layers and overall structure as architecture 3, which explains the close results however architecture 4 had double the number of repetitions which resulted in improved results.\n",
    "- Overall, the less convolution layers we used the less accurate the model was.\n",
    "- A higher number of epoches imporves the results as well but we have to be careful with this paramter since too many epoches can lead to overfitting if there isn't enough data and early stopping is a approach thar can tell us appropriate epochs without overfitting the model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
